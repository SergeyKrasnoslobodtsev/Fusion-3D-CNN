{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc1ecd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-18 12:48:00.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: D:\\workspace\\projects\\freelance\\Fusion3DNet\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root added to path: d:\\workspace\\projects\\freelance\\Fusion3DNet\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import notebook_setup\n",
    "from src.config import INTERIM_DATA_DIR, PROCESSED_DATA_DIR, REPORTS_DIR, EXTERNAL_DATA_DIR, MODELS_DIR\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"4\"\n",
    "\n",
    "BREPNET_NPZ_DIR = INTERIM_DATA_DIR / \"features\" / \"brepnet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0441a3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\workspace\\projects\\freelance\\Fusion3DNet\\data\\interim\\features\\dino\\42. Ejector-01.npz ['views', 'names']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pathlib as p\n",
    "f = next(p.Path(INTERIM_DATA_DIR/'features/dino').glob('*.npz'))  # подставьте конкретный файл, на котором падает\n",
    "with np.load(f) as z:\n",
    "    print(f, z.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5029ea25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего файлов BREP: 129\n",
      "Всего файлов DINO: 129\n",
      "Найдено 128 общих элементов.\n",
      "Вычисление статистики на основе тренировочных данных...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Вычисление статистики: 100%|██████████| 102/102 [00:00<00:00, 302.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранение статистики в D:\\workspace\\projects\\freelance\\Fusion3DNet\\data\\interim\\features\\pooled_brep.json...\n",
      "Загрузка статистики из D:\\workspace\\projects\\freelance\\Fusion3DNet\\data\\interim\\features\\pooled_brep.json\n",
      "Размер обучающего датасета: 102\n",
      "Размер валидационного датасета: 26\n",
      "Shape dino features: torch.Size([8, 384])\n",
      "Ключи в батче: ['views', 'face_matrix', 'item_id']\n",
      "Размер 'views': torch.Size([102, 8, 384])\n",
      "'face_matrix' - это список из 102 тензоров.\n",
      "Размер первого 'face_matrix' в батче: torch.Size([47, 18])\n",
      "ID элементов: ['Защелка АК 4', '42. Ejector-05', 'Зацеп трубки направляющий 4', 'Защелка АК 9', 'Затвор', '43. Extractor-01', '43. Extractor', 'Зацеп трубки направляющий 6', '42. Ejector-09', 'Кожух 3', 'Камера газовая 7', '42. Ejector-08', '44. Extractor Pin-08', '43. Extractor-03', 'Камера газовая 4', '43. Extractor-10', 'Зацеп трубки направляющий 1', '44. Extractor Pin-03', '44. Extractor Pin-05', 'Затвор 2', 'Защелка 5', '42. Silencer Fix-05', '44. Extractor Pin-07', 'Защелка АК 8', 'Камера газовая 1', 'Защелка АК 7', '42. Silencer Fix-02', 'Защелка АК 1', 'Защелка 9', '43. Extractor-06', 'Затвор 7', '43. Extractor-02', '43. Extractor-04', '42. Ejector-10', '42. Ejector-07', '42. Silencer Fix-03', '42. Silencer Fix', 'Защелка 8', 'Камера газовая 3', 'Затвор 3', 'Защелка 3', 'Защелка АК', 'Затвор 9', '44. Extractor Pin-09', 'Защелка АК 2', '44. Extractor Pin-04', '42. Ejector-04', 'Защелка 4', 'Защелка АК 5', 'Затвор 5', 'Камера газовая 9', 'Защелка 1', '42. Silencer Fix-08', 'Зацеп трубки направляющий 10', 'Камера газовая', 'Защелка АК 6', '43. Extractor-09', 'Кожух 1', 'Зацеп трубки направляющий 9', '44. Extractor Pin', '42. Silencer Fix-04', '42. Ejector', 'Камера газовая 8', '42. Ejector-01', 'Зацеп трубки направляющий 8', 'Зацеп трубки направляющий 7', '43. Extractor-07', '42. Silencer Fix-09', 'Затвор 6', '44. Extractor Pin-01', 'Зацеп трубки направляющий 2', 'Защелка 7', '43. Extractor-05', '42. Silencer Fix-10', 'Затвор 1', '42. Silencer Fix-06', '42. Ejector-06', 'Камера газовая 6', 'Защелка АК 3', '42. Ejector-03', 'Защелка 2', '44. Extractor Pin-06', 'Зацеп трубки направляющий 5', '42. Silencer Fix-01', 'Зацеп трубки направляющий 3', 'Затвор 4', 'Кожух 2', 'Камера газовая 2', 'Кожух 4', 'Кожух 10', 'Камера газовая 10', 'Кожух', '43. Extractor-08', '42. Silencer Fix-07', 'Затвор 8', 'Защелка 10', '44. Extractor Pin-02', 'Защелка 6', 'Камера газовая 5', '44. Extractor Pin-10', 'Защелка', 'Зацеп трубки направляющий']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# Импортируем классы из вашего файла\n",
    "from src.modeling.vit_brep_ensemble.data_module.dataset import (\n",
    "    CADItem,\n",
    "    FusionCADDataset,\n",
    "    build_brep_standardizer,\n",
    "    save_stats,\n",
    "    load_stats,\n",
    ")\n",
    "\n",
    "def get_clean_id(filename: str):\n",
    "    name = Path(filename).stem\n",
    "    if name.endswith('.prt'):\n",
    "        name = name[:-4]\n",
    "    return name\n",
    "\n",
    "brep_features_dir = Path(INTERIM_DATA_DIR / \"features/brepnet\")\n",
    "dino_features_dir = Path(INTERIM_DATA_DIR / \"features/dino\")\n",
    "stats_path = Path(INTERIM_DATA_DIR / \"features/pooled_brep.json\")\n",
    "\n",
    "# 2. Собираем объекты CADItem, находя общие файлы\n",
    "brep_files = {p.stem: p for p in brep_features_dir.glob(\"*.npz\")}\n",
    "dino_files = {p.stem: p for p in dino_features_dir.glob(\"*.npz\")}\n",
    "\n",
    "# очистим id от лишних суффиксов\n",
    "brep_files = {get_clean_id(k): v for k, v in brep_files.items()}\n",
    "\n",
    "common_ids = sorted(brep_files.keys() & dino_files.keys())\n",
    "\n",
    "print(f\"Всего файлов BREP: {len(brep_files)}\")\n",
    "print(f\"Всего файлов DINO: {len(dino_files)}\")\n",
    "\n",
    "all_items: List[CADItem] = []\n",
    "for item_id in common_ids:\n",
    "    item = CADItem(\n",
    "        item_id=item_id,\n",
    "        brep_npz_path=brep_files[item_id],\n",
    "        dino_path=dino_files[item_id],\n",
    "    )\n",
    "    all_items.append(item)\n",
    "\n",
    "print(f\"Найдено {len(all_items)} общих элементов.\")\n",
    "\n",
    "# 3. Разделяем на обучающую и валидационную выборки (например, 80/20)\n",
    "train_size = int(0.8 * len(all_items))\n",
    "train_items = all_items[:train_size]\n",
    "val_items = all_items[train_size:]\n",
    "\n",
    "print(\"Вычисление статистики на основе тренировочных данных...\")\n",
    "standardizer = build_brep_standardizer(train_items)\n",
    "print(f\"Сохранение статистики в {stats_path}...\")\n",
    "save_stats(standardizer, stats_path)\n",
    "\n",
    "if stats_path.exists():\n",
    "    print(f\"Загрузка статистики из {stats_path}\")\n",
    "    standardizer = load_stats(stats_path)\n",
    "else:\n",
    "    print(\"Создание и сохранение статистики...\")\n",
    "    standardizer = build_brep_standardizer(train_items)\n",
    "    save_stats(standardizer, stats_path)\n",
    "\n",
    "# 5. Создаем экземпляры датасета\n",
    "train_dataset = FusionCADDataset(\n",
    "    items=train_items,\n",
    "    standardizer=standardizer\n",
    ")\n",
    "val_dataset = FusionCADDataset(\n",
    "    items=val_items,\n",
    "    standardizer=standardizer\n",
    ")\n",
    "\n",
    "print(f\"Размер обучающего датасета: {len(train_dataset)}\")\n",
    "print(f\"Размер валидационного датасета: {len(val_dataset)}\")\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Собирает батч, оставляя тензоры переменной длины (face_matrix) в виде списка.\n",
    "    \"\"\"\n",
    "    views_list = [item['views'] for item in batch]\n",
    "    face_matrix_list = [item['face_matrix'] for item in batch]\n",
    "    item_id_list = [item['item_id'] for item in batch]\n",
    "\n",
    "    \n",
    "    views_batch = torch.stack(views_list, dim=0)\n",
    "\n",
    "    return {\n",
    "        'views': views_batch,\n",
    "        'face_matrix': face_matrix_list,\n",
    "        'item_id': item_id_list\n",
    "    }\n",
    "\n",
    "# 6. Используем DataLoader для итерации по данным\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "print(f'Shape dino features: {train_dataset[1][\"views\"].shape}')\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "print(\"Ключи в батче:\", list(batch.keys()))\n",
    "print(\"Размер 'views':\", batch[\"views\"].shape)\n",
    "# 'face_matrix' теперь - это список, выведем размер первого элемента\n",
    "print(\"'face_matrix' - это список из\", len(batch[\"face_matrix\"]), \"тензоров.\")\n",
    "print(\"Размер первого 'face_matrix' в батче:\", batch[\"face_matrix\"][0].shape)\n",
    "print(\"ID элементов:\", batch[\"item_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f617d721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | dino_encoder | DINOEncoder   | 362 K  | train\n",
      "1 | brep_encoder | BRepShapeHead | 19.0 K | train\n",
      "-------------------------------------------------------\n",
      "381 K     Trainable params\n",
      "0         Non-trainable params\n",
      "381 K     Total params\n",
      "1.525     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка статистики из D:\\workspace\\projects\\freelance\\Fusion3DNet\\data\\interim\\features\\pooled_brep.json\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9bbb6bfc125423d82a5e2445be6c0ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (26x256 and 18x26)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvit_brep_ensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\workspace\\projects\\freelance\\Fusion3DNet\\src\\modeling\\vit_brep_ensemble\\train.py:55\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     47\u001b[39m trainer = pl.Trainer(\n\u001b[32m     48\u001b[39m     max_epochs=EPOCHS,\n\u001b[32m     49\u001b[39m     logger=csv_logger,\n\u001b[32m     50\u001b[39m     callbacks=[checkpoint_callback],\n\u001b[32m     51\u001b[39m     \n\u001b[32m     52\u001b[39m )\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# 6. Запуск обучения\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:49\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     48\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     52\u001b[39m     _call_teardown_hook(trainer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    592\u001b[39m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n\u001b[32m    602\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28mself\u001b[39m._signal_connector.register_signal_handlers()\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1017\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: trainer tearing down\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1054\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1052\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:\n\u001b[32m   1053\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1055\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m   1056\u001b[39m         \u001b[38;5;28mself\u001b[39m.fit_loop.run()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1083\u001b[39m, in \u001b[36mTrainer._run_sanity_check\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1080\u001b[39m call._call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mon_sanity_check_start\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1082\u001b[39m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1083\u001b[39m \u001b[43mval_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1085\u001b[39m call._call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mon_sanity_check_end\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1087\u001b[39m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\pytorch_lightning\\loops\\utilities.py:179\u001b[39m, in \u001b[36m_no_grad_context.<locals>._decorator\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    177\u001b[39m     context_manager = torch.no_grad\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:145\u001b[39m, in \u001b[36m_EvaluationLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28mself\u001b[39m.batch_progress.is_last_batch = data_fetcher.done\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    147\u001b[39m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\pytorch_lightning\\loops\\evaluation_loop.py:437\u001b[39m, in \u001b[36m_EvaluationLoop._evaluation_step\u001b[39m\u001b[34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[39m\n\u001b[32m    431\u001b[39m hook_name = \u001b[33m\"\u001b[39m\u001b[33mtest_step\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer.testing \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvalidation_step\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    432\u001b[39m step_args = (\n\u001b[32m    433\u001b[39m     \u001b[38;5;28mself\u001b[39m._build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[32m    434\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[32m    436\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m output = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[38;5;28mself\u001b[39m.batch_progress.increment_processed()\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[32m    442\u001b[39m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:329\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[32m    332\u001b[39m pl_module._current_fx_name = prev_fx_name\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py:412\u001b[39m, in \u001b[36mStrategy.validation_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model != \u001b[38;5;28mself\u001b[39m.lightning_module:\n\u001b[32m    411\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_redirection(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.lightning_module, \u001b[33m\"\u001b[39m\u001b[33mvalidation_step\u001b[39m\u001b[33m\"\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m412\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\workspace\\projects\\freelance\\Fusion3DNet\\src\\modeling\\vit_brep_ensemble\\models\\ensemble.py:87\u001b[39m, in \u001b[36mContrastiveFusionModel.validation_step\u001b[39m\u001b[34m(self, batch, batch_idx)\u001b[39m\n\u001b[32m     84\u001b[39m brep_embed = embeddings[\u001b[33m\"\u001b[39m\u001b[33mbrep_embed\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# Считаем loss\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_contrastive_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdino_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbrep_embed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28mself\u001b[39m.log(\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, loss, on_step=\u001b[38;5;28;01mFalse\u001b[39;00m, on_epoch=\u001b[38;5;28;01mTrue\u001b[39;00m, prog_bar=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\workspace\\projects\\freelance\\Fusion3DNet\\src\\modeling\\vit_brep_ensemble\\models\\ensemble.py:55\u001b[39m, in \u001b[36mContrastiveFusionModel._compute_contrastive_loss\u001b[39m\u001b[34m(self, dino_embed, brep_embed)\u001b[39m\n\u001b[32m     52\u001b[39m brep_embed = F.normalize(brep_embed, p=\u001b[32m2\u001b[39m, dim=\u001b[32m1\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Матрица косинусного сходства [B, B]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m logits = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdino_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbrep_embed\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m / \u001b[38;5;28mself\u001b[39m.temperature\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Метки для loss-функции: правильные пары находятся на диагонали\u001b[39;00m\n\u001b[32m     58\u001b[39m batch_size = dino_embed.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (26x256 and 18x26)"
     ]
    }
   ],
   "source": [
    "from src.modeling.vit_brep_ensemble import train\n",
    "\n",
    "train.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brepnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
