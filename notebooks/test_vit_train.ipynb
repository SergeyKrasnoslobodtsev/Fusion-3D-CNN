{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc1ecd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-18 20:28:08.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: D:\\workspace\\projects\\freelance\\Fusion3DNet\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root added to path: d:\\workspace\\projects\\freelance\\Fusion3DNet\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import notebook_setup\n",
    "from src.config import INTERIM_DATA_DIR, PROCESSED_DATA_DIR, REPORTS_DIR, EXTERNAL_DATA_DIR, MODELS_DIR\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"4\"\n",
    "\n",
    "BREPNET_NPZ_DIR = INTERIM_DATA_DIR / \"features\" / \"brepnet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0441a3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\workspace\\projects\\freelance\\Fusion3DNet\\data\\interim\\features\\brepnet\\42. Ejector-01.prt.npz ['face_features', 'face_point_grids', 'edge_features', 'coedge_point_grids', 'coedge_features', 'coedge_lcs', 'coedge_scale_factors', 'coedge_reverse_flags', 'next', 'mate', 'face', 'edge']\n",
      "face_features (9, 7) float64\n",
      "face_point_grids (9, 7, 10, 10) float64\n",
      "edge_features (16, 10) float64\n",
      "coedge_point_grids (31, 12, 10) float64\n",
      "coedge_features (31, 1) float64\n",
      "coedge_lcs (31, 4, 4) float64\n",
      "coedge_scale_factors (31,) float64\n",
      "coedge_reverse_flags (31,) float64\n",
      "next (31,) uint32\n",
      "mate (31,) uint32\n",
      "face (31,) uint32\n",
      "edge (31,) uint32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pathlib as p\n",
    "f = next(p.Path(INTERIM_DATA_DIR/'features/brepnet').glob('*.npz'))  # подставьте конкретный файл, на котором падает\n",
    "with np.load(f) as z:\n",
    "    print(f, z.files)\n",
    "    for k in z.files:\n",
    "        print(k, z[k].shape, z[k].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5029ea25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего файлов BREP: 129\n",
      "Всего файлов DINO: 129\n",
      "Найдено 128 общих элементов.\n",
      "Вычисление статистики на основе тренировочных данных...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Вычисление статистики: 100%|██████████| 102/102 [00:00<00:00, 160.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранение статистики в D:\\workspace\\projects\\freelance\\Fusion3DNet\\data\\interim\\features\\pooled_brep.json...\n",
      "Загрузка статистики из D:\\workspace\\projects\\freelance\\Fusion3DNet\\data\\interim\\features\\pooled_brep.json\n",
      "Размер обучающего датасета: 102\n",
      "Размер валидационного датасета: 26\n",
      "Shape dino features: torch.Size([8, 384])\n",
      "Ключи в батче: ['views', 'face_matrix', 'item_id']\n",
      "Размер 'views': torch.Size([102, 8, 384])\n",
      "'face_matrix' - это список из 102 тензоров.\n",
      "Размер первого 'face_matrix' в батче: torch.Size([23, 7])\n",
      "ID элементов: ['42. Silencer Fix-04', '42. Silencer Fix-06', '44. Extractor Pin', '44. Extractor Pin-01', 'Кожух', '42. Ejector-03', 'Защелка АК 2', 'Защелка 10', '43. Extractor-04', '42. Ejector', '43. Extractor-10', '42. Ejector-09', '43. Extractor-05', 'Зацеп трубки направляющий 6', 'Зацеп трубки направляющий 1', '43. Extractor', 'Защелка АК', 'Защелка АК 5', 'Камера газовая 7', 'Камера газовая 5', '43. Extractor-03', 'Камера газовая 3', 'Защелка АК 6', 'Зацеп трубки направляющий 2', 'Камера газовая 9', '42. Silencer Fix-09', 'Затвор 5', '42. Ejector-08', 'Зацеп трубки направляющий 8', 'Защелка 7', '44. Extractor Pin-06', 'Защелка АК 1', '42. Silencer Fix', '44. Extractor Pin-05', 'Зацеп трубки направляющий 10', 'Защелка АК 8', '42. Silencer Fix-10', 'Камера газовая 8', 'Защелка АК 9', '43. Extractor-01', 'Защелка АК 3', 'Зацеп трубки направляющий 4', 'Камера газовая 6', 'Защелка 2', '42. Silencer Fix-02', '43. Extractor-02', '44. Extractor Pin-09', '44. Extractor Pin-10', '43. Extractor-06', 'Зацеп трубки направляющий', '42. Ejector-10', '43. Extractor-09', 'Затвор 6', '42. Ejector-05', 'Кожух 2', '42. Silencer Fix-03', 'Зацеп трубки направляющий 5', '42. Ejector-01', '42. Ejector-06', 'Зацеп трубки направляющий 3', 'Кожух 10', '44. Extractor Pin-02', 'Защелка 8', 'Затвор 3', 'Камера газовая', 'Камера газовая 4', 'Зацеп трубки направляющий 7', 'Защелка 3', '42. Silencer Fix-01', '42. Silencer Fix-08', 'Кожух 4', 'Защелка АК 4', 'Защелка 1', 'Защелка 4', 'Камера газовая 1', '44. Extractor Pin-08', 'Затвор', 'Затвор 1', 'Кожух 3', 'Затвор 8', 'Камера газовая 10', '43. Extractor-08', 'Камера газовая 2', 'Защелка', '42. Silencer Fix-07', 'Защелка АК 7', '44. Extractor Pin-03', 'Затвор 2', 'Зацеп трубки направляющий 9', '42. Silencer Fix-05', 'Затвор 7', 'Кожух 1', 'Защелка 5', 'Защелка 9', 'Затвор 9', '43. Extractor-07', '42. Ejector-04', 'Затвор 4', '44. Extractor Pin-07', 'Защелка 6', '42. Ejector-07', '44. Extractor Pin-04']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# Импортируем классы из вашего файла\n",
    "from src.modeling.vit_brep_ensemble.data_module.dataset import (\n",
    "    CADItem,\n",
    "    FusionCADDataset,\n",
    "    build_brep_standardizer,\n",
    "    save_stats,\n",
    "    load_stats,\n",
    ")\n",
    "\n",
    "def get_clean_id(filename: str):\n",
    "    name = Path(filename).stem\n",
    "    if name.endswith('.prt'):\n",
    "        name = name[:-4]\n",
    "    return name\n",
    "\n",
    "brep_features_dir = Path(INTERIM_DATA_DIR / \"features/brepnet\")\n",
    "dino_features_dir = Path(INTERIM_DATA_DIR / \"features/dino\")\n",
    "stats_path = Path(INTERIM_DATA_DIR / \"features/pooled_brep.json\")\n",
    "\n",
    "# 2. Собираем объекты CADItem, находя общие файлы\n",
    "brep_files = {p.stem: p for p in brep_features_dir.glob(\"*.npz\")}\n",
    "dino_files = {p.stem: p for p in dino_features_dir.glob(\"*.npz\")}\n",
    "\n",
    "# очистим id от лишних суффиксов\n",
    "brep_files = {get_clean_id(k): v for k, v in brep_files.items()}\n",
    "\n",
    "common_ids = sorted(brep_files.keys() & dino_files.keys())\n",
    "\n",
    "print(f\"Всего файлов BREP: {len(brep_files)}\")\n",
    "print(f\"Всего файлов DINO: {len(dino_files)}\")\n",
    "\n",
    "all_items: List[CADItem] = []\n",
    "for item_id in common_ids:\n",
    "    item = CADItem(\n",
    "        item_id=item_id,\n",
    "        brep_npz_path=brep_files[item_id],\n",
    "        dino_path=dino_files[item_id],\n",
    "    )\n",
    "    all_items.append(item)\n",
    "\n",
    "print(f\"Найдено {len(all_items)} общих элементов.\")\n",
    "\n",
    "# 3. Разделяем на обучающую и валидационную выборки (например, 80/20)\n",
    "train_size = int(0.8 * len(all_items))\n",
    "train_items = all_items[:train_size]\n",
    "val_items = all_items[train_size:]\n",
    "\n",
    "print(\"Вычисление статистики на основе тренировочных данных...\")\n",
    "standardizer = build_brep_standardizer(train_items)\n",
    "print(f\"Сохранение статистики в {stats_path}...\")\n",
    "save_stats(standardizer, stats_path)\n",
    "\n",
    "if stats_path.exists():\n",
    "    print(f\"Загрузка статистики из {stats_path}\")\n",
    "    standardizer = load_stats(stats_path)\n",
    "else:\n",
    "    print(\"Создание и сохранение статистики...\")\n",
    "    standardizer = build_brep_standardizer(train_items)\n",
    "    save_stats(standardizer, stats_path)\n",
    "\n",
    "# 5. Создаем экземпляры датасета\n",
    "train_dataset = FusionCADDataset(\n",
    "    items=train_items,\n",
    "    standardizer=standardizer\n",
    ")\n",
    "val_dataset = FusionCADDataset(\n",
    "    items=val_items,\n",
    "    standardizer=standardizer\n",
    ")\n",
    "\n",
    "print(f\"Размер обучающего датасета: {len(train_dataset)}\")\n",
    "print(f\"Размер валидационного датасета: {len(val_dataset)}\")\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Собирает батч, оставляя тензоры переменной длины (face_matrix) в виде списка.\n",
    "    \"\"\"\n",
    "    views_list = [item['views'] for item in batch]\n",
    "    face_matrix_list = [item['face_matrix'] for item in batch]\n",
    "    item_id_list = [item['item_id'] for item in batch]\n",
    "\n",
    "    \n",
    "    views_batch = torch.stack(views_list, dim=0)\n",
    "\n",
    "    return {\n",
    "        'views': views_batch,\n",
    "        'face_matrix': face_matrix_list,\n",
    "        'item_id': item_id_list\n",
    "    }\n",
    "\n",
    "# 6. Используем DataLoader для итерации по данным\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "print(f'Shape dino features: {train_dataset[1][\"views\"].shape}')\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "print(\"Ключи в батче:\", list(batch.keys()))\n",
    "print(\"Размер 'views':\", batch[\"views\"].shape)\n",
    "# 'face_matrix' теперь - это список, выведем размер первого элемента\n",
    "print(\"'face_matrix' - это список из\", len(batch[\"face_matrix\"]), \"тензоров.\")\n",
    "print(\"Размер первого 'face_matrix' в батче:\", batch[\"face_matrix\"][0].shape)\n",
    "print(\"ID элементов:\", batch[\"item_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "912e4437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка статистики из D:\\workspace\\projects\\freelance\\Fusion3DNet\\data\\interim\\features\\pooled_brep.json\n",
      "dino: torch.Size([32, 256]) brep: torch.Size([32, 256])\n"
     ]
    }
   ],
   "source": [
    "from src.modeling.vit_brep_ensemble.models.ensemble import ContrastiveFusionModel\n",
    "from src.modeling.vit_brep_ensemble.data_module.data_loader import FusionDataModule \n",
    "\n",
    "data_module = FusionDataModule(\n",
    "    brep_features_dir=brep_features_dir,\n",
    "    dino_features_dir=dino_features_dir,\n",
    "    stats_path=stats_path,\n",
    "    batch_size=32,    \n",
    ")\n",
    "data_module.setup()\n",
    "batch = next(iter(data_module.train_dataloader()))\n",
    "model = ContrastiveFusionModel(embed_dim=256, learning_rate=1e-4)\n",
    "\n",
    "with torch.no_grad():\n",
    "    embeddings = model(batch)  \n",
    "    dino_embed = embeddings[\"dino_embed\"]\n",
    "    brep_embed = embeddings[\"brep_embed\"]\n",
    "    print(\"dino:\", dino_embed.shape, \"brep:\", brep_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f617d721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\lightning_fabric\\connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "d:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:508: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "d:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\pytorch_lightning\\utilities\\model_summary\\model_summary.py:231: Precision bf16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n",
      "\n",
      "  | Name            | Type                | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | dino_encoder    | DINOViewEncoder     | 428 K  | train\n",
      "1 | face_encoder    | FaceGeometryEncoder | 58.4 K | train\n",
      "2 | projection_head | Sequential          | 164 K  | train\n",
      "----------------------------------------------------------------\n",
      "650 K     Trainable params\n",
      "0         Non-trainable params\n",
      "650 K     Total params\n",
      "2.603     Total estimated model params size (MB)\n",
      "27        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7fe2c909a449858c5a566292ebafa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "d:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 26. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2096198961da4ce89ee14bcd93107462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 64. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "d:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\pytorch_lightning\\utilities\\data.py:79: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 38. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf885957d9445a5865e9ab63adea494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb027646c674e88b4aba97d55d23ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f67c85364c41ccbf8557b616ebbe3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa00ea735b4442784bf003dd578c656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4ce1f2c3a0490c9b1d79e6cf44e1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be535afd0c94bb184d8a455fa21cce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ea182dc82743fdb4be8847011b41c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd7290f92b34c76b69d105258ce9a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a19a9df6b64011bf54356c12ec6b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e5a4e72f63462599751310c8e7c933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b345282331449d6a1709744f99dce36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9374c7e2274bf4b415bffea41d5bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd683cb2f1114a65b234adf05c61c29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936bc872c7644c2d92661891608d38a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af762f9e74244cd89f95c17a5e981d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a497cf744924594997948a6c5aafb0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b600630128084e6883348e6124751565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ec093a66734f4981ac489becb7f7a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa957b576fc04807b2a1709dc2b41c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8fe3a8ed537435ba1278db97c0975bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52ab079e803460a883a7717190a0c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.modeling.vit_brep_ensemble import train_enhanced\n",
    "\n",
    "train_enhanced.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96f063be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ключи в батче: ['views', 'face_matrix', 'item_id']\n",
      "Размер 'views': torch.Size([32, 8, 384])\n",
      "Размер первого 'face_matrix' в батче: torch.Size([5, 7])\n",
      "ID элементов: ['42. Ejector-08', '43. Extractor-04', '43. Extractor-08', 'Камера газовая 3', 'Защелка 1', 'Затвор 3', '44. Extractor Pin-08', 'Защелка АК 7', 'Зацеп трубки направляющий 10', 'Камера газовая 8', 'Затвор 8', 'Зацеп трубки направляющий 4', '44. Extractor Pin-02', '42. Ejector-03', 'Затвор 7', 'Кожух', '43. Extractor-06', 'Зацеп трубки направляющий 8', '44. Extractor Pin', '44. Extractor Pin-10', 'Защелка 5', 'Затвор 5', '42. Ejector-01', 'Защелка АК', 'Камера газовая 9', 'Защелка 10', '43. Extractor-03', 'Кожух 4', '42. Silencer Fix-09', 'Защелка АК 3', '43. Extractor-10', 'Затвор 1']\n"
     ]
    }
   ],
   "source": [
    "from src.modeling.vit_brep_ensemble.data_module.enhanced_data_loader import EnhancedFusionDataModule\n",
    "\n",
    "data_module = EnhancedFusionDataModule(\n",
    "    brep_features_dir=brep_features_dir,\n",
    "    dino_features_dir=dino_features_dir,\n",
    "    stats_path=stats_path)\n",
    "\n",
    "data_module.setup()\n",
    "batch = next(iter(data_module.train_dataloader()))\n",
    "\n",
    "print(\"Ключи в батче:\", list(batch.keys()))\n",
    "print(\"Размер 'views':\", batch[\"views\"].shape)\n",
    "print(\"Размер первого 'face_matrix' в батче:\", batch[\"face_matrix\"][0].shape)\n",
    "print(\"ID элементов:\", batch[\"item_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38222bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Используем устройство: cpu\n",
      "📦 Загружаем обученную модель...\n",
      "📊 Подготавливаем данные...\n",
      "🔄 Строим индекс эмбеддингов...\n",
      "  Обрабатываем train split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train embeddings:   0%|          | 0/2 [00:00<?, ?it/s]d:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Extracting train embeddings: 100%|██████████| 2/2 [00:09<00:00,  4.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Обрабатываем val split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting val embeddings: 100%|██████████| 1/1 [00:09<00:00,  9.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Индекс построен: 128 моделей, размерность 128\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models\\\\search_index.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 77\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# Сохраняем индекс для будущего использования\u001b[39;00m\n\u001b[32m     76\u001b[39m index_path = Path(\u001b[33m\"\u001b[39m\u001b[33mmodels/search_index.npz\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[43msimulator\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# Примеры поиска\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m🔍 Примеры поиска:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\workspace\\projects\\freelance\\Fusion3DNet\\src\\modeling\\vit_brep_ensemble\\search_simulator.py:246\u001b[39m, in \u001b[36mSearchSimulator.save_index\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m    235\u001b[39m embeddings_np = {\n\u001b[32m    236\u001b[39m     item_id: embedding.numpy() \n\u001b[32m    237\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m item_id, embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embeddings_cache.items()\n\u001b[32m    238\u001b[39m }\n\u001b[32m    240\u001b[39m index_data = {\n\u001b[32m    241\u001b[39m     \u001b[33m'\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m'\u001b[39m: embeddings_np,\n\u001b[32m    242\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mitem_ids\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mself\u001b[39m.item_ids,\n\u001b[32m    243\u001b[39m     \u001b[33m'\u001b[39m\u001b[33membedding_dim\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlist\u001b[39m(embeddings_np.values())[\u001b[32m0\u001b[39m].shape[\u001b[32m0\u001b[39m]\n\u001b[32m    244\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msavez_compressed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mindex_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m💾 Индекс сохранён: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\numpy\\lib\\npyio.py:710\u001b[39m, in \u001b[36msavez_compressed\u001b[39m\u001b[34m(file, *args, **kwds)\u001b[39m\n\u001b[32m    647\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_savez_compressed_dispatcher)\n\u001b[32m    648\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msavez_compressed\u001b[39m(file, *args, **kwds):\n\u001b[32m    649\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    650\u001b[39m \u001b[33;03m    Save several arrays into a single file in compressed ``.npz`` format.\u001b[39;00m\n\u001b[32m    651\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    708\u001b[39m \n\u001b[32m    709\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m710\u001b[39m     \u001b[43m_savez\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\numpy\\lib\\npyio.py:736\u001b[39m, in \u001b[36m_savez\u001b[39m\u001b[34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001b[39m\n\u001b[32m    733\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    734\u001b[39m     compression = zipfile.ZIP_STORED\n\u001b[32m--> \u001b[39m\u001b[32m736\u001b[39m zipf = \u001b[43mzipfile_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mw\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m namedict.items():\n\u001b[32m    739\u001b[39m     fname = key + \u001b[33m'\u001b[39m\u001b[33m.npy\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\.miniconda\\envs\\brepnet\\Lib\\site-packages\\numpy\\lib\\npyio.py:103\u001b[39m, in \u001b[36mzipfile_factory\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mzipfile\u001b[39;00m\n\u001b[32m    102\u001b[39m kwargs[\u001b[33m'\u001b[39m\u001b[33mallowZip64\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev\\.miniconda\\envs\\brepnet\\Lib\\zipfile.py:1295\u001b[39m, in \u001b[36mZipFile.__init__\u001b[39m\u001b[34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[39m\n\u001b[32m   1293\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m   1294\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1295\u001b[39m         \u001b[38;5;28mself\u001b[39m.fp = io.open(file, filemode)\n\u001b[32m   1296\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m   1297\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'models\\\\search_index.npz'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from src.modeling.vit_brep_ensemble.models.self_supervised_ensemble import SelfSupervisedFusionModel\n",
    "from src.modeling.vit_brep_ensemble.data_module.enhanced_data_loader import EnhancedFusionDataModule\n",
    "from src.modeling.vit_brep_ensemble.search_simulator import SearchSimulator\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "\n",
    "def interactive_search(simulator: SearchSimulator):\n",
    "    \"\"\"Интерактивный поиск\"\"\"\n",
    "    \n",
    "    print(\"\\n🎮 Интерактивный поиск (введите 'quit' для выхода)\")\n",
    "    \n",
    "    while True:\n",
    "        query_id = input(\"\\nВведите ID модели для поиска: \").strip()\n",
    "        \n",
    "        if query_id.lower() in ['quit', 'exit', 'q']:\n",
    "            break\n",
    "            \n",
    "        if query_id not in simulator.embeddings_cache: # type: ignore\n",
    "            print(f\"❌ Модель '{query_id}' не найдена в индексе\")\n",
    "            \n",
    "            # Показываем доступные ID (первые 10)\n",
    "            available_ids = list(simulator.embeddings_cache.keys())[:10] # type: ignore\n",
    "            print(f\"Доступные ID (первые 10): {available_ids}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            top_k = int(input(\"Количество результатов (по умолчанию 10): \") or \"10\")\n",
    "        except ValueError:\n",
    "            top_k = 10\n",
    "        \n",
    "        results = simulator.search_similar(query_id, top_k=top_k)\n",
    "        \n",
    "        print(f\"\\n🎯 Результаты поиска для '{query_id}':\")\n",
    "        for rank, (item_id, similarity) in enumerate(results, 1):\n",
    "            print(f\"  {rank:2d}. {item_id} (схожесть: {similarity:.4f})\")\n",
    "\n",
    "\n",
    "best_checkpoint_path = MODELS_DIR / \"enhanced_fusion\" / \"fusion-epoch=09-val_loss=0.017.ckpt\"\n",
    "brep_features_dir = Path(INTERIM_DATA_DIR / \"features/brepnet\")\n",
    "dino_features_dir = Path(INTERIM_DATA_DIR / \"features/dino\")\n",
    "stats_path = Path(INTERIM_DATA_DIR / \"features/pooled_brep.json\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🚀 Используем устройство: {device}\")\n",
    "\n",
    "# Загружаем модель\n",
    "print(\"📦 Загружаем обученную модель...\")\n",
    "model = SelfSupervisedFusionModel.load_from_checkpoint(best_checkpoint_path)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# Подготавливаем данные\n",
    "print(\"📊 Подготавливаем данные...\")\n",
    "data_module = EnhancedFusionDataModule(\n",
    "    brep_features_dir=brep_features_dir,\n",
    "    dino_features_dir=dino_features_dir,\n",
    "    stats_path=stats_path,\n",
    "    batch_size=64,  # Увеличиваем для быстрого извлечения эмбеддингов\n",
    "    num_workers=8\n",
    ")\n",
    "data_module.setup()\n",
    "\n",
    "# Создаём симулятор\n",
    "simulator = SearchSimulator(model, data_module, device)\n",
    "\n",
    "# Строим индекс\n",
    "simulator.build_index(use_train=True, use_val=True)\n",
    "\n",
    "# Сохраняем индекс для будущего использования\n",
    "index_path = Path(MODELS_DIR / \"search_index.npz\")\n",
    "simulator.save_index(index_path)\n",
    "\n",
    "# Примеры поиска\n",
    "print(\"\\n🔍 Примеры поиска:\")\n",
    "\n",
    "# Берём случайную модель для демонстрации\n",
    "query_id = np.random.choice(simulator.item_ids)\n",
    "print(f\"\\n📝 Запрос: {query_id}\")\n",
    "\n",
    "# Поиск топ-10\n",
    "results = simulator.search_similar(query_id, top_k=10)\n",
    "\n",
    "print(f\"\\n🏆 Топ-10 похожих моделей:\")\n",
    "for rank, (item_id, similarity) in enumerate(results, 1):\n",
    "    print(f\"  {rank:2d}. {item_id} (схожесть: {similarity:.4f})\")\n",
    "\n",
    "# Визуализация\n",
    "simulator.visualize_search_results(\n",
    "    query_id, \n",
    "    top_k=10, \n",
    "    save_path=Path(f\"results/search_results_{query_id}.png\")\n",
    ")\n",
    "\n",
    "# Оценка качества\n",
    "print(\"\\n📈 Оценка качества поиска...\")\n",
    "metrics = simulator.evaluate_retrieval(top_k=10)\n",
    "\n",
    "print(\"\\n📊 Метрики качества:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "# Интерактивный поиск\n",
    "interactive_search(simulator)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brepnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
