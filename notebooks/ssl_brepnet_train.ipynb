{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b93ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import notebook_setup\n",
    "from src.config import INTERIM_DATA_DIR, PROCESSED_DATA_DIR, REPORTS_DIR, EXTERNAL_DATA_DIR, MODELS_DIR\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d3bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# OCC\n",
    "from OCC.Core.STEPControl import STEPControl_Reader\n",
    "from OCC.Core.IFSelect import IFSelect_RetDone\n",
    "from OCC.Core.TopExp import TopExp_Explorer\n",
    "from OCC.Core.TopAbs import TopAbs_FACE, TopAbs_IN\n",
    "from OCC.Core.BRepAdaptor import BRepAdaptor_Surface\n",
    "from OCC.Core.BRepClass import BRepClass_FaceClassifier\n",
    "from OCC.Core.gp import gp_Pnt2d\n",
    "\n",
    "def ensure_uv_2d(x):\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "    if x.size == 0:\n",
    "        return np.zeros((0, 2), dtype=np.float32)\n",
    "    if x.ndim == 2 and x.shape[1] == 2:\n",
    "        return x\n",
    "    if x.ndim == 1 and x.shape[0] == 2:\n",
    "        return x.reshape(1, 2)\n",
    "    return x.reshape(-1, 2)\n",
    "\n",
    "def sample_uv_extended(resolution, extend=0.1):\n",
    "    u = np.linspace(-extend, 1 + extend, resolution)\n",
    "    v = np.linspace(-extend, 1 + extend, resolution)\n",
    "    uu, vv = np.meshgrid(u, v, indexing='ij')\n",
    "    return np.stack([uu.flatten(), vv.flatten()], axis=-1)\n",
    "\n",
    "def compute_sdf(inside_points, outside_points):\n",
    "    inside = ensure_uv_2d(inside_points)\n",
    "    outside = ensure_uv_2d(outside_points)\n",
    "\n",
    "    if inside.shape[0] == 0 and outside.shape[0] == 0:\n",
    "        return np.zeros((0, 2), dtype=np.float32), np.zeros((0,), dtype=np.float32)\n",
    "    if inside.shape[0] == 0:\n",
    "        return outside, -np.zeros((outside.shape[0],), dtype=np.float32)\n",
    "    if outside.shape[0] == 0:\n",
    "        return inside, np.zeros((inside.shape[0],), dtype=np.float32)\n",
    "\n",
    "    inside_tree = KDTree(outside)\n",
    "    outside_tree = KDTree(inside)\n",
    "    d_inside, _ = inside_tree.query(inside)\n",
    "    d_outside, _ = outside_tree.query(outside)\n",
    "\n",
    "    sdf_inside = d_inside.astype(np.float32)\n",
    "    sdf_outside = -d_outside.astype(np.float32)\n",
    "    sdf_points = np.concatenate([inside, outside], axis=0)\n",
    "    sdf_values = np.concatenate([sdf_inside, sdf_outside], axis=0)\n",
    "    return ensure_uv_2d(sdf_points), sdf_values.astype(np.float32)\n",
    "\n",
    "def bias_sample_sdf(sdf_points, sdf_values, n_samples, boundary_ratio=0.4):\n",
    "    pts = ensure_uv_2d(sdf_points)\n",
    "    vals = np.asarray(sdf_values, dtype=np.float32).reshape(-1)\n",
    "    if pts.shape[0] == 0:\n",
    "        return pts, vals\n",
    "    idx = np.argsort(np.abs(vals))\n",
    "    nb = int(n_samples * boundary_ratio)\n",
    "    nb = max(0, min(nb, idx.size))\n",
    "    i_boundary = idx[:nb]\n",
    "    i_pool = idx[nb:]\n",
    "    if i_pool.size:\n",
    "        i_pool = np.random.permutation(i_pool)\n",
    "    need_rand = max(0, n_samples - nb)\n",
    "    i_sel = np.concatenate([i_boundary, i_pool[:min(need_rand, i_pool.size)]], axis=0)\n",
    "    i_sel = i_sel.astype(int)\n",
    "    return pts[i_sel], vals[i_sel]\n",
    "\n",
    "# ---------- привязка к реальной грани ----------\n",
    "def query_cad_kernel_face(face, uv_samples):\n",
    "    \"\"\"\n",
    "    Делим UV на inside/outside относительно ТРИМОВ грани через CAD-ядро.\n",
    "    \"\"\"\n",
    "    uv = ensure_uv_2d(uv_samples)\n",
    "    surf = BRepAdaptor_Surface(face)\n",
    "    u0, u1 = surf.FirstUParameter(), surf.LastUParameter()\n",
    "    v0, v1 = surf.FirstVParameter(), surf.LastVParameter()\n",
    "    clf = BRepClass_FaceClassifier()\n",
    "\n",
    "    mask = []\n",
    "    for uv_ in uv:\n",
    "        uu = float(u0 + float(uv_[0]) * (u1 - u0))\n",
    "        vv = float(v0 + float(uv_[1]) * (v1 - v0))\n",
    "        p2d = gp_Pnt2d(uu, vv)\n",
    "        clf.Perform(face, p2d, 1e-9)\n",
    "        mask.append(clf.State() == TopAbs_IN)\n",
    "\n",
    "    mask = np.array(mask, dtype=bool)\n",
    "    inside  = uv[mask]\n",
    "    outside = uv[~mask]\n",
    "    return ensure_uv_2d(inside), ensure_uv_2d(outside)\n",
    "\n",
    "def compute_xyz_from_uv_face(face, uv_coords):\n",
    "    uv = ensure_uv_2d(uv_coords)\n",
    "    if uv.shape[0] == 0:\n",
    "        return np.zeros((0, 3), dtype=np.float32)\n",
    "    surf = BRepAdaptor_Surface(face)\n",
    "    u0, u1 = surf.FirstUParameter(), surf.LastUParameter()\n",
    "    v0, v1 = surf.FirstVParameter(), surf.LastVParameter()\n",
    "    uu = u0 + uv[:, 0] * (u1 - u0)\n",
    "    vv = v0 + uv[:, 1] * (v1 - v0)\n",
    "    out = np.zeros((uv.shape[0], 3), dtype=np.float32)\n",
    "    for i in range(uv.shape[0]):\n",
    "        p = surf.Value(float(uu[i]), float(vv[i]))\n",
    "        out[i, 0] = p.X(); out[i, 1] = p.Y(); out[i, 2] = p.Z()\n",
    "    return out\n",
    "\n",
    "# ---------- загрузка STEP и обход граней ----------\n",
    "def load_shape(step_path: str):\n",
    "    r = STEPControl_Reader()\n",
    "    assert r.ReadFile(step_path) == IFSelect_RetDone, \"STEP read failed\"\n",
    "    r.TransferRoots()\n",
    "    return r.OneShape()\n",
    "from OCC.Extend import TopologyUtils\n",
    "def iter_faces(shape):\n",
    "    top_exp = TopologyUtils.TopologyExplorer(shape, ignore_orientation=True)\n",
    "    for face in top_exp.faces():\n",
    "        yield face\n",
    "\n",
    "# ---------- быстрая проверка на 1-й грани ----------\n",
    "def quick_sdf_check_all(step_path: str, res=128, extend=0.1, n_samples=500, show_first_k=2):\n",
    "    shape = load_shape(step_path)\n",
    "    faces = list(iter_faces(shape))\n",
    "    assert len(faces) > 0, \"Нет граней в модели\"\n",
    "\n",
    "    all_sdf_uv   = []   # список [ [n_i,2], ... ]\n",
    "    all_sdf_vals = []   # список [ [n_i],   ... ]\n",
    "    all_samp_uv  = []   # список [ [n_samples,2], ... ]\n",
    "    all_samp_sdf = []   # список [ [n_samples],   ... ]\n",
    "    all_targ_xyz = []   # список [ [n_samples,3], ... ]\n",
    "\n",
    "    for i, face in enumerate(faces):\n",
    "        if i >= 3:\n",
    "            break\n",
    "        uv = sample_uv_extended(resolution=res, extend=extend)            # [M,2] torch\n",
    "        inside, outside = query_cad_kernel_face(face, uv)                 # [*,2]\n",
    "        sdf_pts, sdf_vals = compute_sdf(inside, outside)                  # [M',2],[M']\n",
    "        samp_uv, samp_sdf = bias_sample_sdf(sdf_pts, sdf_vals,\n",
    "                                            n_samples=n_samples, boundary_ratio=0.4)\n",
    "        targ_xyz = compute_xyz_from_uv_face(face, samp_uv)                # [n_samples,3]\n",
    "\n",
    "        all_sdf_uv.append(sdf_pts)\n",
    "        all_sdf_vals.append(sdf_vals)\n",
    "        all_samp_uv.append(samp_uv)\n",
    "        all_samp_sdf.append(samp_sdf)\n",
    "        all_targ_xyz.append(targ_xyz)\n",
    "\n",
    "        # необязательная визуализация для первых k граней\n",
    "        # if i < show_first_k:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(10,4))\n",
    "        sc = ax[0].scatter(sdf_pts[:,0], sdf_pts[:,1],\n",
    "                            c=sdf_vals, s=4, cmap=\"coolwarm\")\n",
    "        fig.colorbar(sc, ax=ax[0], label=\"SDF (UV)\")\n",
    "        ax[0].set_title(f\"Face {i}: SDF на UV-сетке\")\n",
    "        ax[0].set_xlabel(\"u\"); ax[0].set_ylabel(\"v\")\n",
    "\n",
    "        sc2 = ax[1].scatter(samp_uv[:,0], samp_uv[:,1],\n",
    "                                c=samp_sdf, s=8, cmap=\"coolwarm\")\n",
    "        fig.colorbar(sc2, ax=ax[1], label=\"SDF (выборка у границы)\")\n",
    "        ax[1].set_title(f\"Face {i}: выборка у границы\")\n",
    "        ax[1].set_xlabel(\"u\"); ax[1].set_ylabel(\"v\")\n",
    "        plt.tight_layout(); plt.show()\n",
    "\n",
    "    # сводка\n",
    "    total_points = sum(v for v in all_sdf_vals)\n",
    "    print(f\"Граней: {len(faces)}; всего SDF-точек на сетках: {total_points}; \"\n",
    "          f\"выборок у границы на грань: {n_samples}\")\n",
    "\n",
    "    return {\n",
    "        \"faces_count\": len(faces),\n",
    "        \"sdf_grid_uv_list\": all_sdf_uv,        # список torch тензоров [n_i,2]\n",
    "        \"sdf_grid_vals_list\": all_sdf_vals,    # список torch тензоров [n_i]\n",
    "        \"sampled_uv_list\": all_samp_uv,        # список torch тензоров [n_samples,2]\n",
    "        \"sampled_sdf_list\": all_samp_sdf,      # список torch тензоров [n_samples]\n",
    "        \"target_xyz_list\": all_targ_xyz        # список torch тензоров [n_samples,3]\n",
    "    }\n",
    "\n",
    "STEPS_DIR = PROCESSED_DATA_DIR / \"dataset_129\" / \"stp\"\n",
    "\n",
    "step_files = stems = {p for p in STEPS_DIR.glob(\"*.stp\")}\n",
    "\n",
    "stp = list(step_files)[15]\n",
    "print(f\"Using STEP file: {stp}\")\n",
    "out = quick_sdf_check_all(str(stp), res=128, extend=0.1, n_samples=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2c37d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modeling.SSL_BrepNet import extract_features\n",
    "\n",
    "FEATURES_LIST_PATH = EXTERNAL_DATA_DIR / \"feature_lists\" / \"all.json\"\n",
    "STEPS_DIR = PROCESSED_DATA_DIR / \"dataset_129\" / \"stp\"\n",
    "extract_features.run(\n",
    "    step_path_dir=STEPS_DIR,\n",
    "    feature_list_path=FEATURES_LIST_PATH,\n",
    "    num_workers=0,\n",
    "    force_regeneration=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ec7577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modeling.SSL_BrepNet import build_dataset_file\n",
    "BREPNET_NPZ_DIR = PROCESSED_DATA_DIR / \"dataset_129\" / \"features\" / \"brep\"\n",
    "STATS_BREPNET = PROCESSED_DATA_DIR / \"dataset_129\" / \"dataset_brepnet_stats.json\"\n",
    "os.makedirs(BREPNET_NPZ_DIR, exist_ok=True)\n",
    "build_dataset_file.run(\n",
    "    brepnet_dir=BREPNET_NPZ_DIR,\n",
    "    output_file=STATS_BREPNET,\n",
    "    validation_split=0.1,\n",
    "    test_split=0.1,\n",
    "    random_seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ef3b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "BREPNET_NPZ_DIR = PROCESSED_DATA_DIR / \"dataset_129\" / \"features\" / \"brep\"\n",
    "import numpy as np\n",
    "npz_files = list(BREPNET_NPZ_DIR.glob(\"*.npz\"))\n",
    "print(f\"Всего .npz файлов: {len(npz_files)}\")\n",
    "\n",
    "with np.load(npz_files[0]) as data:\n",
    "    for k, v in data.items():\n",
    "        print(f\"{k}: {v.shape}, dtype={v.dtype}, min={v.min() if v.size>0 else 'N/A'}, max={v.max() if v.size>0 else 'N/A'}\")\n",
    "\n",
    "# BREPNET_NPZ_DIR = PROCESSED_DATA_DIR / \"dataset_129\" / \"features\" / \"all_sdf_with_normals\"\n",
    "# npz_files = list(BREPNET_NPZ_DIR.glob(\"*.npz\"))\n",
    "# print(f\"Всего .npz файлов: {len(npz_files)}\")\n",
    "\n",
    "# with np.load(npz_files[0]) as data:\n",
    "#     for k, v in data.items():\n",
    "#         print(f\"{k}: {v.shape}, dtype={v.dtype}, min={v.min() if v.size>0 else 'N/A'}, max={v.max() if v.size>0 else 'N/A'}\")\n",
    "\n",
    "# os.makedirs(BREPNET_NPZ_DIR, exist_ok=True)\n",
    "\n",
    "# for npz_path in npz_files:\n",
    "#     with np.load(npz_path) as data:\n",
    "#         uv_faces = data['uv_faces']          # [n,2]\n",
    "#         sdf_faces = data['sdf_faces']    # [n]\n",
    "#     np.savez_compressed(BREPNET_NPZ_DIR / npz_path.name, uv_faces=uv_faces, sdf_faces=sdf_faces)\n",
    "#     print(f\"Обработан файл {npz_path}, добавлены нормали.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e42a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from types import SimpleNamespace\n",
    "from src.modeling.SSL_BrepNet.model.encoder import CustomBRepEncoder\n",
    "from src.modeling.SSL_BrepNet.model.decoder import ConditionalDecoder\n",
    "\n",
    "BREPNET_NPZ_DIR = PROCESSED_DATA_DIR / \"dataset_129\" / \"features\" / \"brep\"\n",
    "SDF_NPZ_DIR = PROCESSED_DATA_DIR / \"dataset_129\" / \"features\" / \"all_sdf_with_normals\"\n",
    "npz_brep_files = list(BREPNET_NPZ_DIR.glob(\"*.npz\"))\n",
    "npz_sdf_files = list(SDF_NPZ_DIR.glob(\"*.npz\"))\n",
    "\n",
    "\n",
    "\n",
    "D = np.load(npz_files[0])\n",
    "SDF =np.load(npz_files[0])\n",
    "\n",
    "data = SimpleNamespace(\n",
    "    vertices=torch.from_numpy(D[\"vertex\"].astype(np.float32)),         # [n_v, 3]\n",
    "    edges=torch.from_numpy(D[\"edge_features\"].astype(np.float32)),     # [n_e, edge_feat_dim]\n",
    "    faces=torch.from_numpy(D[\"face_features\"].astype(np.float32)),     # [n_f, face_feat_dim]\n",
    "    edge_to_vertex=torch.from_numpy(D[\"edge_to_vertex\"].astype(np.int64)), # [2, n_e]\n",
    "    face_to_edge=torch.from_numpy(D[\"face_to_edge\"][::-1].astype(np.int64)),   # [2, n_f]\n",
    "    face_to_face=torch.from_numpy(D[\"face_to_face\"].astype(np.int64)),     # [2, M]\n",
    ")\n",
    "\n",
    "\n",
    "encoder = CustomBRepEncoder(\n",
    "    v_in_width=data.vertices.shape[1],             \n",
    "    e_in_width=data.edges.shape[1], \n",
    "    f_in_width=data.faces.shape[1], \n",
    "    out_width=64,\n",
    "    num_layers=2,\n",
    "    use_attention=True\n",
    ").eval()\n",
    "\n",
    "# проброс признаков\n",
    "with torch.no_grad():\n",
    "    emb = encoder(data)\n",
    "\n",
    "print(\"OK. encoder output shape:\", tuple(emb.shape) if isinstance(emb, torch.Tensor) else type(emb))\n",
    "\n",
    "decoder = ConditionalDecoder(latent_size=64, hidden_dims=[1024, 1024, 1024, 1024])\n",
    "\n",
    "data_sdf = np.load(npz_sdf_files[0])\n",
    "# uv_faces: (9, 500, 2), dtype=float32, min=-0.10000000149011612, max=1.100000023841858\n",
    "# sdf_faces: (9, 500), dtype=float32, min=-0.39380156993865967, max=0.4913385510444641\n",
    "\n",
    "sdf_uv = torch.from_numpy(data_sdf[\"uv_faces\"].astype(np.float32))        # [n_faces, n_samples, 2]\n",
    "sdf_vals = torch.from_numpy(data_sdf[\"sdf_faces\"].astype(np.float32))      # [n_faces, n_samples]\n",
    "print(f\"emb shape: {emb.shape}, sdf_uv shape: {sdf_uv.shape}, sdf_vals shape: {sdf_vals.shape}\")\n",
    "with torch.no_grad():\n",
    "    pred_sdf = decoder(sdf_uv[0], emb[0])   # [n_faces, n_samples]\n",
    "\n",
    "print(\"OK. decoder output shape:\", tuple(pred_sdf.shape) if isinstance(pred_sdf, torch.Tensor) else type(pred_sdf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "BREPNET_NPZ_DIR = PROCESSED_DATA_DIR / \"dataset_129\" / \"features\" / \"brep\"\n",
    "SDF_NPZ_DIR = PROCESSED_DATA_DIR / \"dataset_129\" / \"features\" / \"all_sdf_with_normals\"\n",
    "DT_PATH = PROCESSED_DATA_DIR / \"dataset_129\" / \"preprocessed_data.pt\"\n",
    "\n",
    "brep_files = {p.name: p for p in BREPNET_NPZ_DIR.glob(\"*.npz\")}\n",
    "sdf_files = {p.name: p for p in SDF_NPZ_DIR.glob(\"*.npz\")}\n",
    "\n",
    "common_names = sorted(set(brep_files.keys()) & set(sdf_files.keys()))\n",
    "\n",
    "preprocessed_data = []\n",
    "for fname in common_names:\n",
    "    D = np.load(brep_files[fname])\n",
    "    S = np.load(sdf_files[fname])\n",
    "\n",
    "    # Признаки для encoder\n",
    "    data = SimpleNamespace(\n",
    "        vertices=torch.from_numpy(D[\"vertex\"].astype(np.float32)),\n",
    "        edges=torch.from_numpy(D[\"edge_features\"].astype(np.float32)),\n",
    "        faces=torch.from_numpy(D[\"face_features\"].astype(np.float32)),\n",
    "        edge_to_vertex=torch.from_numpy(D[\"edge_to_vertex\"].astype(np.int64)),\n",
    "        face_to_edge=torch.from_numpy(D[\"face_to_edge\"][::-1].astype(np.int64)),\n",
    "        face_to_face=torch.from_numpy(D[\"face_to_face\"].astype(np.int64)),\n",
    "    )\n",
    "    # Получаем эмбеддинг\n",
    "    with torch.no_grad():\n",
    "        emb = encoder(data)\n",
    "        if emb.ndim == 2:\n",
    "            emb = emb.mean(dim=0)\n",
    "\n",
    "    # SDF-выборки\n",
    "    sampled_points = torch.from_numpy(S[\"uv_faces\"].astype(np.float32))  # [n, 2]\n",
    "    sampled_sdf = torch.from_numpy(S[\"sdf_faces\"].astype(np.float32))    # [n]\n",
    "\n",
    "    preprocessed_data.append((fname, emb, sampled_points, sampled_sdf))\n",
    "\n",
    "# Сохраняем датасет для обучения\n",
    "torch.save(preprocessed_data, DT_PATH)\n",
    "print(f\"Датасет собран: {len(preprocessed_data)} моделей\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a93836",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modeling.SSL_BrepNet.dataset import BrepNetDataset\n",
    "STATS_BREPNET = PROCESSED_DATA_DIR / \"dataset_129\" / \"dataset_brepnet_stats.json\"\n",
    "SDF_NPZ_DIR = PROCESSED_DATA_DIR / \"dataset_129\" / \"features\" / \"all_sdf_with_normals\"\n",
    "BREP_NPZ_DIR = PROCESSED_DATA_DIR / \"dataset_129\" / \"features\" / \"brep\"\n",
    "\n",
    "train_dataset = BrepNetDataset(STATS_BREPNET, BREP_NPZ_DIR, SDF_NPZ_DIR, split=\"training_set\")\n",
    "val_dataset = BrepNetDataset(STATS_BREPNET, BREP_NPZ_DIR, SDF_NPZ_DIR, split=\"validation_set\")\n",
    "test_dataset = BrepNetDataset(STATS_BREPNET, BREP_NPZ_DIR, SDF_NPZ_DIR, split=\"test_set\")\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}, Test samples: {len(test_dataset)}\")\n",
    "print(f\"Example data keys: {list(vars(train_dataset[0]).keys())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d0d730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from src.modeling.SSL_BrepNet.sdf_compute import SDFComputer\n",
    "\n",
    "\n",
    "class BRepAutoEncoderModule(pl.LightningModule):\n",
    "    def __init__(self, encoder, decoder, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.lr = lr\n",
    "        self.save_hyperparameters(ignore=['encoder', 'decoder'])\n",
    "\n",
    "    def compute_loss(self, predicted, target_xyz, target_sdf):\n",
    "        pred_xyz, pred_sdf = predicted[:, :3], predicted[:, 3]\n",
    "        xyz_loss = torch.nn.functional.mse_loss(pred_xyz, target_xyz)\n",
    "        sdf_loss = torch.nn.functional.mse_loss(pred_sdf, target_sdf)\n",
    "        return xyz_loss + sdf_loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        device = self.device if hasattr(self, \"device\") else self.encoder.parameters().__next__().device\n",
    "        for key, value in vars(batch).items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                setattr(batch, key, value.to(device))\n",
    "\n",
    "        data = batch\n",
    "        embedding = self.encoder(data)\n",
    "        sampled_points = data.sdf_uv.squeeze(0)\n",
    "        sampled_sdf = data.sdf_vals.squeeze(0)\n",
    "\n",
    "        total_loss = 0.0\n",
    "        total_sdf_loss = 0.0\n",
    "        total_xyz_loss = 0.0\n",
    "\n",
    "        for i in range(sampled_points.shape[0]):\n",
    "            uv = sampled_points[i]\n",
    "            sdf = sampled_sdf[i]\n",
    "            emb_face = embedding[i]\n",
    "            # Исправление: добавляем batch-ось если нужно\n",
    "            if uv.ndim == 1:\n",
    "                uv = uv.unsqueeze(0)\n",
    "            predicted = self.decoder(uv, emb_face)\n",
    "            target_xyz = self.compute_xyz_from_uv(uv).float()\n",
    "            pred_xyz, pred_sdf = predicted[:, :3], predicted[:, 3]\n",
    "\n",
    "            print(\"uv:\", uv)\n",
    "            print(\"sdf:\", sdf)\n",
    "            print(\"emb_face:\", emb_face)\n",
    "            print(\"predicted:\", predicted)\n",
    "            print(\"target_xyz:\", target_xyz)\n",
    "\n",
    "            if torch.isnan(pred_xyz).any() or torch.isnan(pred_sdf).any() or torch.isnan(target_xyz).any() or torch.isnan(sdf).any():\n",
    "                print(\"NaN detected in prediction or target!\")\n",
    "            if torch.isinf(pred_xyz).any() or torch.isinf(pred_sdf).any() or torch.isinf(target_xyz).any() or torch.isinf(sdf).any():\n",
    "                print(\"Inf detected in prediction or target!\")\n",
    "\n",
    "            xyz_loss = torch.nn.functional.mse_loss(pred_xyz, target_xyz)\n",
    "            sdf_loss = torch.nn.functional.mse_loss(pred_sdf, sdf)\n",
    "            total_loss += xyz_loss + sdf_loss\n",
    "            total_xyz_loss += xyz_loss\n",
    "            total_sdf_loss += sdf_loss\n",
    "\n",
    "        total_loss = total_loss / sampled_points.shape[0]\n",
    "        total_xyz_loss = total_xyz_loss / sampled_points.shape[0]\n",
    "        total_sdf_loss = total_sdf_loss / sampled_points.shape[0]\n",
    "\n",
    "        self.log('train_loss', total_loss, batch_size=1)\n",
    "        self.log('train_xyz_loss', total_xyz_loss, batch_size=1)\n",
    "        self.log('train_sdf_loss', total_sdf_loss, batch_size=1)\n",
    "        return total_loss\n",
    "    \n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        device = self.device if hasattr(self, \"device\") else self.encoder.parameters().__next__().device\n",
    "        for key, value in vars(batch).items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                setattr(batch, key, value.to(device))\n",
    "\n",
    "        data = batch\n",
    "        embedding = self.encoder(data)\n",
    "        sampled_points = data.sdf_uv.squeeze(0)\n",
    "        sampled_sdf = data.sdf_vals.squeeze(0)\n",
    "\n",
    "        total_loss = 0.0\n",
    "        total_sdf_loss = 0.0\n",
    "        total_xyz_loss = 0.0\n",
    "\n",
    "        for i in range(sampled_points.shape[0]):\n",
    "            uv = sampled_points[i]\n",
    "            sdf = sampled_sdf[i]\n",
    "            emb_face = embedding[i]\n",
    "            if uv.ndim == 1:\n",
    "                uv = uv.unsqueeze(0)\n",
    "            predicted = self.decoder(uv, emb_face)\n",
    "            target_xyz = self.compute_xyz_from_uv(uv).float()\n",
    "            pred_xyz, pred_sdf = predicted[:, :3], predicted[:, 3]\n",
    "            xyz_loss = torch.nn.functional.mse_loss(pred_xyz, target_xyz)\n",
    "            sdf_loss = torch.nn.functional.mse_loss(pred_sdf, sdf)\n",
    "            total_loss += xyz_loss + sdf_loss\n",
    "            total_xyz_loss += xyz_loss\n",
    "            total_sdf_loss += sdf_loss\n",
    "\n",
    "        total_loss = total_loss / sampled_points.shape[0]\n",
    "        total_xyz_loss = total_xyz_loss / sampled_points.shape[0]\n",
    "        total_sdf_loss = total_sdf_loss / sampled_points.shape[0]\n",
    "\n",
    "        self.log('val_loss', total_loss, prog_bar=True, batch_size=1)\n",
    "        self.log('val_xyz_loss', total_xyz_loss, prog_bar=True, batch_size=1)\n",
    "        self.log('val_sdf_loss', total_sdf_loss, prog_bar=True, batch_size=1)\n",
    "        return total_loss\n",
    "\n",
    "    def compute_xyz_from_uv(self, uv_coords):\n",
    "        \"\"\" Простейшая проекция UV в 3D пространство (z=0).\n",
    "            спиздили у китайцев\n",
    "        \"\"\"\n",
    "        x = uv_coords[:, 0]  # x координата\n",
    "        y = uv_coords[:, 1]  # y координата\n",
    "        z = torch.zeros_like(x)  # z координата\n",
    "\n",
    "        return torch.stack([x, y, z], dim=-1)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(list(self.encoder.parameters()) + list(self.decoder.parameters()), lr=self.lr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf90f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modeling.SSL_BrepNet.model.encoder import CustomBRepEncoder\n",
    "from src.modeling.SSL_BrepNet.model.decoder import ConditionalDecoder\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "encoder = CustomBRepEncoder(\n",
    "    v_in_width=train_dataset[0].vertices.shape[1],\n",
    "    e_in_width=train_dataset[0].edges.shape[1],\n",
    "    f_in_width=train_dataset[0].faces.shape[1],\n",
    "    out_width=64,\n",
    "    num_layers=2,\n",
    "    use_attention=True\n",
    ")\n",
    "decoder = ConditionalDecoder(latent_size=64, hidden_dims=[1024, 1024, 1024, 1024])\n",
    "module = BRepAutoEncoderModule(encoder, decoder)\n",
    "\n",
    "def brepnet_collate(batch):\n",
    "    out = {}\n",
    "    for key in vars(batch[0]).keys():\n",
    "        values = [getattr(b, key) for b in batch]\n",
    "        if key in [\"edge_to_vertex\", \"face_to_edge\", \"face_to_face\"]:\n",
    "            out[key] = values[0]\n",
    "        elif isinstance(values[0], torch.Tensor):\n",
    "            # Если размерности совпадают — stack, иначе — список\n",
    "            shapes = [v.shape for v in values]\n",
    "            if all(s == shapes[0] for s in shapes):\n",
    "                stacked = torch.stack(values)\n",
    "                if stacked.shape[0] == 1 and key in [\"vertices\", \"edges\", \"faces\"]:\n",
    "                    out[key] = stacked.squeeze(0)\n",
    "                else:\n",
    "                    out[key] = stacked\n",
    "            else:\n",
    "                out[key] = values  # список тензоров разной длины\n",
    "        elif isinstance(values[0], np.ndarray):\n",
    "            shapes = [v.shape for v in values]\n",
    "            if all(s == shapes[0] for s in shapes):\n",
    "                out[key] = np.stack(values)\n",
    "            else:\n",
    "                out[key] = values\n",
    "        else:\n",
    "            out[key] = values\n",
    "    return SimpleNamespace(**out)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn=brepnet_collate)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, collate_fn=brepnet_collate)\n",
    "csv_logger = CSVLogger(save_dir=REPORTS_DIR, name=\"ssl_autoencoder_logs\")\n",
    "    \n",
    "trainer = pl.Trainer(max_epochs=1, logger=[csv_logger])\n",
    "trainer.fit(module, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f2686db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results: [tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]]), tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]]), tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]]), tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]]), tensor([[nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan]])]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.modeling.SSL_BrepNet.model.encoder import CustomBRepEncoder\n",
    "from src.modeling.SSL_BrepNet.model.decoder import ConditionalDecoder\n",
    "\n",
    "# Пути к сохранённым весам\n",
    "ENCODER_PATH = MODELS_DIR / \"epoch=4-step=520.ckpt\"\n",
    "\n",
    "ckpt = torch.load(ENCODER_PATH, map_location=\"cpu\")\n",
    "encoder_state_dict = ckpt[\"state_dict\"]\n",
    "# Оставляем только ключи, относящиеся к encoder\n",
    "encoder_state_dict = {k.replace(\"encoder.\", \"\"): v for k, v in encoder_state_dict.items() if k.startswith(\"encoder.\")}\n",
    "\n",
    "encoder = CustomBRepEncoder(\n",
    "    v_in_width=train_dataset[0].vertices.shape[1],\n",
    "    e_in_width=train_dataset[0].edges.shape[1],\n",
    "    f_in_width=train_dataset[0].faces.shape[1],\n",
    "    out_width=64,\n",
    "    num_layers=2,\n",
    "    use_attention=True\n",
    ")\n",
    "encoder.load_state_dict(encoder_state_dict)\n",
    "encoder.eval()\n",
    "\n",
    "# decoder = ConditionalDecoder(latent_size=64, hidden_dims=[1024, 1024, 1024, 1024])\n",
    "# decoder.load_state_dict(torch.load(DECODER_PATH, map_location=\"cpu\"))\n",
    "# decoder.eval()\n",
    "\n",
    "# Поиск: прогон нового образца\n",
    "def search(sample):\n",
    "    with torch.no_grad():\n",
    "        emb = encoder(sample)\n",
    "        results = []\n",
    "        for i in range(sample.sdf_uv.shape[0]):\n",
    "            uv = sample.sdf_uv[i]\n",
    "            emb_face = emb[i]\n",
    "            pred = decoder(uv, emb_face)\n",
    "            results.append(pred)\n",
    "        return results\n",
    "\n",
    "# Пример использования\n",
    "sample = train_dataset[0]\n",
    "results = search(sample)\n",
    "print(\"Search results:\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brepnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
