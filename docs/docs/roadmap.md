# Дорожная карта v2 — Поиск 3D моделей и поиск внутри модели

> Цель: построить поисковик 3D‑моделей «как на маркетплейсах» — по модели, по тексту и по ручным фильтрам — **без ручной разметки**, с подсветкой отличий и **поиском внутри модели** (локализация фич по текстовому запросу).

## Ключевые решения и изменения относительно v1
- Переходим к **мультимодели «две башни»**: 3D‑энкодер (B‑Rep/UV+граф) + текст‑энкодер. Контрастивное обучение (CLIP‑style) на **авто‑описаниях** из STEP/B‑Rep.
- Добавляем **атрибутную голову** (multi‑label/регрессия по бинам) для устойчивости и объяснимости.
- Вводим **пер‑лицевые/пер‑патч эмбеддинги + MIL/attention‑pooling** → поиск *внутри* модели и heatmap релевантности.
- Данные: помимо UV и графа, готовим **структурированные признаки** (отверстия, типы поверхностей, симметрии, габариты, скругления, при наличии — материал/плотность/вес). Из них формируем **контролируемые текстовые описания** (RU).
- Индексы: **глобальный** ANN по моделям + **локальные** индексы по лицам для активной модели.
- Материал: учитываем как **мягкий фильтр** (часто отсутствует в STEP). Если есть плотность — используем как прокси.

---

## Этап 1 — Подготовка данных и авто‑описания
**Выход:** нормализованный датасет с B‑Rep, UV‑тайлами, графами, пер‑лицевыми признаками, JSON‑атрибутами и текстовыми описаниями.

**Задачи**
1. **STEP→B‑Rep парсинг** (OpenCascade/pythonOCC/ocp): faces/edges/coedges, связи next/prev/mate, локальные UV‑параметризации.
2. **UV‑представление граней**: рендер карт нормалей/кривизн/масштаба в фиксированном размере (напр. 128×128) с маской области.
3. **Граф смежности** (face–face / face–edge), нормализация масштаба модели, центрирование.
4. **Авто‑признаки** из B‑Rep:
   - типы поверхностей (plane/cylinder/cone/sphere/torus),
   - отверстия (сквозные/глухие, диаметры/оси, внутренние проволоки),
   - габариты bbox, объём, площадь, отношения осей,
   - скругления/фаски (count, r_min/r_max),
   - симметрии (осевая/плоскости), паттерны (венец/ряд отверстий),
   - материал/плотность, если экспортированы; иначе `unknown` + `confidence`.
5. **JSON‑схема** атрибутов (версионированная) и **контролируемые текстовые описания** (RU/EN) по шаблонам + синонимам (Controlled NL). Числовые значения → **бины** (лог‑шкала) для обучения.
6. **Аугментации B‑Rep** для SSL: скрытие/слияние граней, jitter параметров поверхностей, лёгкие фаски/скругления, перестановки обходов coedge (с сохранением топологии).

**DoD**: конвертированы ≥95% корпуса; валидатор геометрии проходит; JSON/тексты детерминированы; имеются unit‑тесты на детект отверстий/типов поверхностей/симметрий.

---

## Этап 2 — Мультимодальное обучение (3D↔текст) + атрибуты

**Выход:** единое пространство эмбеддингов для моделей и текстов; глобальные и пер-гранные вектора для поиска и локализации.  

---

### Модель

- **3D-энкодер**
  - **UV-поток (CNN)** → локальные признаки граней `h_uv_f`
  - **BRepNet** → топологические/геометрические признаки граней `h_brep_f`
  - **Fusion (MLP/concat)** → объединённый эмбеддинг грани `h_f`
  - **Графовый блок (GNN/GAT)** над `h_f` → уточнённые признаки
  - **Attention / MIL-pooling** → глобальный эмбеддинг `z_model ∈ R^d`
  - **Выходы:**  
    - локальные эмбеддинги граней `z_face ∈ R^d`  
    - глобальный эмбеддинг модели `z_model ∈ R^d`

- **Текст-энкодер**
  - Компактный Transformer / контекстный BoW → `z_txt ∈ R^d`

- **Головы**
  1. **Проекционная** — выравнивает 3D и текстовое пространство  
  2. **Атрибутная** — предсказание авто-признаков  
     - multi-label категории  
     - числовые бины (Huber/Smooth-L1)

---

### Лоссы

- `L_clip`: двунаправленный InfoNCE( `z_model` ↔ `z_txt` )
- `L_attr`: BCE/CE для категориальных признаков + Huber/Smooth-L1 для бинов
- *(опц.)* `L_tri / ArcFace`: дискриминация 3D↔3D (instance discrimination)

**Итог**

`L = λ1 * L_clip + λ2 * L_attr (+ λ3 * L_tri)`

**Фишки стабильности**
- Маскирование отсутствующих атрибутов (материал/плотность) в `L_attr`.
- **Hard negatives**: пары «одинаковая форма класса (оба цилиндры), разные отверстия/диаметры/отношения размеров».
- Нормализация эмбеддингов (L2), температура τ≈0.07.

**DoD**: Text→3D Recall@{1,5,10} растёт на валидации; 3D→3D NDCG/Recall@k выше baseline SSL без текста; атрибуты предсказываются с mAP/F1 ≥ целевого порога.

---

## Этап 3 — Межмодельный поиск (глобальный ANN) и API
**Выход:** сервис top‑k по модели/тексту с быстрым откликом.

**Задачи**
1. Индексация глобальных `z_model` в **FAISS** (HNSW/IVF‑PQ). Размер эмбеддинга d=256/512.
2. **Поиск по модели**: загрузка запроса (STEP) → `z_model` → top‑k соседей.
3. **Поиск по тексту**: запрос → `z_txt` → top‑k моделей.
4. **Re‑rank**: штрафы за несоответствие критичных атрибутов (напр. «сквозное отверстие»), учёт симметрий/отношений размеров.
5. **API**: `/embed_model`, `/embed_text`, `/search_models`, `/batch_search`, журналирование метрик (latency, R@k).

**DoD**: P95 latency в целевом SLA; стабильность индекса под обновления; метрики мониторятся.

---

## Этап 4 — Внутримодельный поиск (локализация фич) и подсветка
**Выход:** heatmap релевантности по граням и список найденных фич под текстовый запрос.

**Задачи**
1. Предрасчёт/онлайн‑расчёт пер‑лицевых `z_face` для активной модели; **локальный индекс** (HNSW/k‑d tree).
2. Скоринг `s_i = cos(z_face_i, z_txt)` + **сглаживание по графу** (1–2 шага).
3. **Группировка** соседних «горячих» граней в фичи (отверстие/паз/бобышка); карточки с атрибутами (тип, диаметр, глубина, ось, толщина стенки).
4. UI: heatmap, выделение фич, экспорты снимков/отчётов.

**DoD**: корректная локализация на контрольном наборе; время ответа интерактивное; UX‑тест пройден.

---

## Этап 5 — Парсер запросов и фильтры
**Выход:** гибрид текст→вектор + строгие фильтры по вычислимым признакам.

**Задачи**
1. `query_parser_ru` (правила/регулярки/синонимы): извлечение сущностей «форма/отверстия/диаметр/ось/материал/габариты/симметрии» + толерансы.
2. **Материал**: трактуем как мягкий фильтр; если есть плотность — используем пороговые эвристики; иначе не блокируем, но понижаем.
3. **Фильтры UI**: число/типы отверстий, радиусы, bbox, симметрии, min wall thickness, резьба и т.д. (всё из B‑Rep/атрибутов).

**DoD**: разбор ≥90% типовых фраз; интеграция с ранкером; A/B‑прирост качества выдачи.

---

## Этап 6 — Выравнивание и сравнение моделей (подсветка отличий)
**Выход:** отчёт «что добавлено/удалено/изменено» между двумя моделями.

**Задачи**
1. CAD↔CAD выравнивание (feature‑based ICP на ориентированных гранях; без триангуляции).
2. Поиск соответствий граней (cost = косинусная близость `z_face` + топологические штрафы; Hungarian/Min‑Cost Flow).
3. Heatmap и список отличий (unmatched/изменённые грани; расхождения нормалей/кривизн/offset в мировых координатах).

**DoD**: корректные карты отличий на бенчмарке пар «оригинал↔модификация».

---

## Этап 7 — Оценка качества и валидация
**Метрики**
- Text→3D: Recall@{1,5,10}, mAP@k.
- 3D→3D: Recall@k, NDCG.
- Локализация: AP/IoU по фичам (если доступна синтетическая/частичная разметка), proxy‑метрики по атрибутам.
- Продуктовые: CTR/сохранение сеансов, время до первой релевантной.

**Валидация**:
- Синтетические пары «оригинал/вариант» (фаски/скругления/отверстия/сдвиги размеров).
- Human‑in‑the‑loop проверка карточек фич и подсветки.

---

## Этап 8 — Продактизация и инфраструктура
**Инженерия**
- Микросервисы по SOLID/KISS: `brep_loader`, `geom_features`, `uv_encoder`, `graph_encoder`, `text_encoder`, `multimodal_trainer`, `faiss_service`, `query_parser_ru`, `ranker`, `diff_highlighter`, `viz_api`.
- Конфиги (YAML), детерминированные пайплайны, версионирование датасета/моделей.
- **Оффлайн‑сборка**: контейнер с предустановленными зависимостями (OCCT, FAISS, PyTorch), без доступа к интернету (учёт ограничений рабочего ПК).
- Мониторинг: latency/Recall, дрейф запросов, алерты.
- Лицензии и данные: проверка ограничений (некоммерческие/проприетарные компоненты), аудит экспорта STEP.

**API (минимум)**
- `POST /embed_model`, `POST /embed_text`
- `POST /search_models` (query: текст/STEP, k, фильтры)
- `POST /search_in_model` (text, model_id)
- `POST /diff` (model_a, model_b)

---

## Бэклог / улучшения
- Мультиязычные шаблоны (RU) + датаклининг для редких терминов.
- Проекция 3D‑эмбеддингов в CLIP‑текст‑пространство (zero‑shot без авто‑описаний) — как дополнительный режим.
- Учет технологичности: минимальные радиусы, ГОСТ‑классы допусков, резьбы.
- Обучение с частичной ручной проверкой описаний (active learning).

---

## План спринтов (пример)
- **S1–S2**: Этап 1 (парсер, UV, граф, отверстия/поверхности, JSON+тексты, аугментации).
- **S3–S4**: Этап 2 (две башни + атрибуты, первичный training; базовые метрики).
- **S5**: Этап 3 (FAISS, API поиска по модели/тексту, re‑rank).
- **S6**: Этап 4 (локализация и heatmap), **S7**: Этап 5 (парсер+фильтры), **S8**: Этап 6 (diff).
- **S9**: Этап 7–8 (метрики, продактизация, оффлайн‑контейнер, мониторинг).


**побочный материал для этапа**

1) [UV-Net: Learning from Boundary Representations](https://openaccess.thecvf.com/content/CVPR2021/papers/Jayaraman_UV-Net_Learning_From_Boundary_Representations_CVPR_2021_paper.pdf?utm_source=chatgpt.com), 


2) [Self-Supervised Representation Learning for CAD](https://openaccess.thecvf.com/content/CVPR2023/papers/Jones_Self-Supervised_Representation_Learning_for_CAD_CVPR_2023_paper.pdf?utm_source=chatgpt.com)

3) [Реализация статьи на GitHub Self-Supervised Representation Learning for CAD](https://github.com/zhenshihaowanlee/Self-supervised-BRep-learning-for-CAD/blob/main/Example_data/sampled_data.py)

4) [Self-supervised Graph Neural Network for Mechanical CAD Retrieval](https://arxiv.org/html/2406.08863v2?utm_source=chatgpt.com)

5) [Библиотека для эффективного поиска по сходству и кластеризации плотных векторов](https://github.com/facebookresearch/faiss?utm_source=chatgpt.com)

6) [Манула Faiss](https://faiss.ai/index.html?utm_source=chatgpt.com)

7) [Faiss: A library for efficient similarity search](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/?utm_source=chatgpt.com)
